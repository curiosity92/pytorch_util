version: '2.2'
services:
  pytorch_util_service_1:
    image: pytorch_util_service:22.06.15.1418
    runtime: nvidia
    environment:
      RPC_SERVER_PORT: 42000
      PYTORCH_UTIL_LOG_LEVEL: INFO
    volumes:
      - /data/wxt/pytorch_util/pytorch_util/log:/pytorch_util_service/pytorch_util/log
    ports:
      - 42001:42000
    restart: always
    mem_limit: 3G
    command:
      python server.py

  pytorch_util_service_2:
    image: pytorch_util_service:22.06.15.1418
    runtime: nvidia
    environment:
      RPC_SERVER_PORT: 42000
      PYTORCH_UTIL_LOG_LEVEL: INFO
    volumes:
      - /data/wxt/pytorch_util/pytorch_util/log:/pytorch_util_service/pytorch_util/log
    ports:
      - 42002:42000
    restart: always
    mem_limit: 3G
    command:
 #      --gpus=all
 #      --runtime=nvidia
      python server.py

  pytorch_util_service_nginx:
    restart: always
    image: nginx
    ports:
      - 42000:42000
    volumes:
      - ./log:/var/log/nginx
      - ./nginx_model.conf:/etc/nginx/nginx.conf
    logging:
      driver: json-file
      options:
        max-size: 100m
        max-file: '10'
